<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sanskrit Language Research | Ompraksh's Personal Portfolio</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        .chart-container {
            width: 100%;
            height: 600px;
            margin: 0 auto;
            border-radius: 15px;
        }

        .subsection-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: space-between;
            margin: 20px 0;
            gap: 20px;
        }

        .subsection {
            flex: 1 1 calc(50% - 20px);
            text-align: center;
        }

        .subsection-chart {
            width: 100%;
            height: 300px;
            margin: 0 auto;
            border-radius: 15px;
        }

        .subsection h3 {
            margin-top: 10px;
            font-size: 1.2em;
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <div class="container">
            <ul class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="skills.html">Skills</a></li>
                <li><a href="projects.html">Projects</a></li>
                <li><a href="research.html">Healthcare Research</a></li>
                <li><a href="research1.html">Sanskrit Language Research</a></li>
                <li><a href="interest_topics.html">Interest Topics</a></li>
                <li><a href="contact.html">Contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Research Section -->
    <section class="research">
        <h2>Sanskrit Language Research</h2> 
        <section class="research2">
            <h2>Integrating Sanskrit Language with Data Science: Machine Learning Approaches for Text Analysis</h2>
            <h3>Independent Research</h3>
            <section> 
                <a href="Sample of Work.pdf" download="Research-Paper" class="download-button">Download PDF or View Research Overview & Progress Report</a> 
            </section> 
            <section> 
                <h2>Introduction</h2> 
                <p class="p1">
                    <strong><em>Sanskrit, often referred to as the "Mother of All Languages," is one of the oldest and most structured languages, 
                    renowned for its cultural, philosophical, and linguistic depth.</em></strong> Its grammatical precision, particularly in <strong><em>Panini’s Ashtadhyayi,</em></strong> 
                    offers a foundation for computational linguistics, making it a valuable resource for modern <strong>data science and machine learning (ML)</strong> techniques. 
                    This research explores how Sanskrit can be integrated with ML and artificial intelligence (AI) to develop advanced <strong>Natural Language Processing 
                    (NLP)</strong> tools. By leveraging the structured nature of Sanskrit grammar, this study aims to preserve its cultural heritage, analyze linguistic 
                    patterns, and create models for machine translation, sentiment analysis, and topic modeling. Additionally, <strong><em>Sanskrit’s systematic syntax 
                    has been explored in the context of programming languages,</em></strong> offering innovative approaches to designing algorithms and computational models.
                </p>
                <section>
                    <p><strong><em>Panini's Ashtadhyayi is an ancient Sanskrit text composed by the grammarian Panini around the 5th century BCE. 
                    It is a comprehensive work that outlines the rules of Sanskrit grammar in a highly systematic and algorithmic manner. 
                    The Ashtadhyayi consists of eight chapters and is considered one of the most precise and structured grammatical works ever created. 
                    Panini’s approach is based on morphology, where words are broken down into smaller components like roots, prefixes, and suffixes. 
                    His rules are formulated in a way that is highly adaptable to computational models, 
                    making it influential in the field of computational linguistics and natural language processing (NLP).</em></strong></p>
                </section>
                <section>
                    <p class="p1">
                        The research also looks to bridge the gap between ancient knowledge and contemporary technological advancements. 
                        It focuses on digitizing Sanskrit texts, applying machine learning for linguistic analysis, and exploring interdisciplinary 
                        applications in philosophy and AI. Furthermore, the study investigates future possibilities, such as speech recognition, 
                        quantum computing, and AI-driven research tools, which hold great potential for enhancing both the preservation and advancement of 
                        Sanskrit. Ultimately, this work aims to contribute to the integration of Sanskrit with modern technology, ensuring that one of the 
                        world’s oldest languages continues to evolve in the digital era.
                    </p>
                </section>
            </section>
            <section>
                <h2>Purpose and Scope</h2>
                <section>
                   <h3 style="text-align: left;">Purpose:</h3>
                </section>
                <section>
                    <p class="p1">
                        1. Explore the integration of data science, machine learning (ML), and artificial intelligence (AI) techniques with Sanskrit for linguistic analysis, cultural preservation, and the development of advanced natural language processing (NLP) tools.
                    </p>
                        <p class="p1">
                            2. Bridge the gap between ancient linguistic knowledge, particularly the insights found in Panini’s Ashtadhyayi, and modern computational technologies.
                        </p>
                        <p class="p1">
                            3. Preserve Sanskrit texts and explore innovative applications such as machine translation, sentiment analysis, topic modeling, and other NLP tasks, specifically for Sanskrit language data.
                        </p>
                        <p class="p1">
                            4. Develop computational models and AI-driven tools that enhance the processing and understanding of Sanskrit, contributing to both linguistic analysis and cultural preservation.
                        </p>
                </section>
                <section>
                   <h3 style="text-align: left;">Scope:</h3>
                </section>
                <section>
                    <p class="p1">
                        1. Curate, digitize, and standardize Sanskrit datasets for computational analysis and processing.
                    </p>
                    <p class="p1">
                        2. Apply machine learning and AI techniques to analyze linguistic patterns and structures in Sanskrit texts.
                    </p>
                    <p class="p1">
                        3. Develop machine learning models specifically designed for NLP tasks such as machine translation, sentiment analysis, syntactic analysis, and topic modeling for Sanskrit.
                    </p>
                    <p class="p1">
                        4. Investigate interdisciplinary applications of Sanskrit in cultural preservation, philosophy, and AI ethics.
                    </p>
                    <p class="p1">
                        5. Explore future possibilities such as Sanskrit’s integration into speech recognition, quantum computing, and AI-powered research tools.
                    </p>
                    <p class="p1">
                        6. Address both the theoretical and practical aspects of integrating Sanskrit with modern computational techniques to create technologies that preserve and advance the language in the digital age.
                    </p>
                 </section>

            <!-- Main Donut Chart -->
            <section style="margin-bottom: 50px;">
                <div id="main-donut" class="chart-container"></div>
            </section>

            <!-- Subsection Charts in Two Rows -->
            <section class="subsection-container">
                <div class="subsection">
                    <div id="dataScienceSubsection" class="subsection-chart"></div>
                    <h3>Data Science</h3>
                </div>
                <div class="subsection">
                    <div id="machineLearningSubsection" class="subsection-chart"></div>
                    <h3>Machine Learning</h3>
                </div>
                <div class="subsection">
                    <div id="aiTechniquesSubsection" class="subsection-chart"></div>
                    <h3>Artificial Intelligence</h3>
                </div>
                <div class="subsection">
                    <div id="interdisciplinarySubsection" class="subsection-chart"></div>
                    <h3>Interdisciplinary Studies</h3>
                </div>
            </section>

            <!-- Research Progress Distribution Chart -->
            <section style="margin-top: 50px;">
                <div id="progress-donut" class="chart-container"></div>
            </section>

            <script src="https://code.highcharts.com/highcharts.js"></script>
            <script src="https://code.highcharts.com/highcharts-3d.js"></script>
            <script src="https://code.highcharts.com/modules/exporting.js"></script>
            <script>
                // Main Donut Chart
                Highcharts.chart('main-donut', {
                    chart: {
                        type: 'pie',
                        options3d: { enabled: true, alpha: 55, beta: 0, depth: 60 },
                        backgroundColor: '#f9f9f9',
                    },
                    title: { text: 'Technical Subsections of Research',
                            style: { fontSize: '22px', fontWeight: 'bold', color: '#333' },
                    },
                    subtitle: {
                        text: 'Data Science Techniques, Machine Learning Techniques, Artificial Intelligence Techniques and Interdisciplinary Applications',
                        style: {
                            fontSize: '16px',
                            color: '#666'
                        }
                    },
                    plotOptions: {
                        pie: {
                            innerSize: 130,
                            depth: 55,
                            dataLabels: {
                                enabled: true,
                                format: '<b>{point.name}</b>: {point.percentage:.1f}%',
                                style: { color: 'black', fontWeight: 'bold', fontSize: '14px' },
                            },
                            allowPointSelect: true,
                            cursor: 'pointer',
                            showInLegend: true,
                        },
                    },
                    legend: {
                        itemStyle: {
                            fontSize: '14px',
                            fontWeight: 'bold',
                            color: '#444'
                        }
                    },
                    series: [{
                        name: 'Research Breakdown',
                        data: [
                            { name: 'Data Science Techniques', y: 30 },
                            { name: 'Machine Learning Techniques', y: 40 },
                            { name: 'AI Techniques', y: 20 },
                            { name: 'Interdisciplinary Applications', y: 10 },
                        ],
                    }],
                    exporting: { enabled: true },
                    credits: { enabled: false },
                });
                
                // Subsection Charts
                const chartsData = {
                    dataScienceSubsection: [['Text Collection', 6], ['Preprocessing', 7], ['Feature Extraction', 7], ['Data Augmentation', 5], ['Dimensionality Reduction', 5]],
                    machineLearningSubsection: [['Supervised Learning', 8], ['Unsupervised Learning', 6], ['Deep Learning', 10], ['NLP Tasks', 10], ['Transfer Learning', 4], ['Reinforcement Learning', 2]],
                    aiTechniquesSubsection: [['Natural Language Generation', 3], ['AI for Education', 4], ['Semantic Analysis',  4], ['Symbolic AI', 5], ['Knowledge Representation', 1], ['Cognitive Computing', 1], ['Computer Vision for Text Analysis', 2]],
                    interdisciplinarySubsection: [['Programming Language Design', 4], ['Cultural Preservation', 3], ['Computational Philology', 1], ['Philosophical AI', 1],  ['Digital Humanities', 1]],
                };

                for (const [id, data] of Object.entries(chartsData)) {
                    Highcharts.chart(id, {
                        chart: {
                            type: 'pie',
                            options3d: { enabled: true, alpha: 45, beta: 0 },
                            backgroundColor: '#f9f9f9',
                        },
                        title: { text: '' },
                        plotOptions: {
                            pie: {
                                innerSize: 80,
                                depth: 50,
                                dataLabels: {
                                    enabled: true,
                                    format: '<b>{point.name}</b>: {point.percentage:.1f}%',
                                    style: { color: 'black', fontWeight: 'bold', fontSize: '12px'},
                                },
                                allowPointSelect: true,
                                cursor: 'pointer',
                            },
                        },
                        series: [{ name: 'Subsection Breakdown', data }],
                        exporting: { enabled: true },
                        credits: { enabled: false },
                    });
                }

                // Research Progress Donut Chart
                Highcharts.chart('progress-donut', {
                    chart: {
                        type: 'pie',
                        options3d: { enabled: true, alpha: 55, beta: 0, depth: 60 },
                        backgroundColor: '#f9f9f9',
                    },
                    title: {
                        text: 'Component Weightage in Research Methodology',
                        style: { fontSize: '22px', fontWeight: 'bold', color: '#333' },
                    },
                    subtitle: {
                        text: 'A detailed breakdown of Component Weightage in Research ',
                        style: {
                            fontSize: '16px',
                            color: '#666'
                        }
                    },
                    plotOptions: {
                        pie: {
                            allowPointSelect: true,
                            cursor: 'pointer',
                            depth: 55,
                            innerSize: '30%',
                            dataLabels: {
                                enabled: true,
                                format: '<b>{point.name}</b>: {point.percentage:.1f}%',
                                style: { fontSize: '14px', fontWeight: 'bold', color: '#333' },
                            },
                            showInLegend: true,
                        },
                    },
                    legend: {
                        itemStyle: {
                            fontSize: '14px',
                            fontWeight: 'bold',
                            color: '#444'
                        }
                    },
                    series: [{
                        name: 'Progress',
                        data: [
                            { name: 'Topic Selection', y: 10 },
                            { name: 'Literature Review and Existing Research', y: 10, sliced: true, selected: true },
                            { name: 'Data Cleaning, Preprocessing, and Feature Extraction', y: 10 },
                            { name: 'Machine Learning Techniques Studied', y: 15 },
                            { name: 'Data Science Techniques Studied', y: 10 },
                            { name: 'AI and Interdisciplinary Techniques Studied', y: 10 },
                            { name: 'Model Development', y: 10 },
                            { name: 'Challenges Identified', y: 5 },
                            { name: 'Future Scope Identified', y: 5 },
                            { name: 'Outcomes', y: 5 },
                            { name: 'Potential Applications', y: 5 },
                            { name: 'Documentation & Writing', y: 5 },
                        ],
                    }],
                    exporting: { enabled: true },
                    credits: { enabled: false },
                });
            </script>
            <section>
                <p class="p1">
                    The <strong>weightage of the components</strong> in the research paper is distributed to reflect their importance. 
                    <strong>Topic selection</strong> is given <strong>10%,</strong> as it sets the foundation. The <strong>literature review and existing research</strong> receives <strong>10%,</strong> providing the theoretical background. 
                    <strong>Data cleaning, preprocessing, and feature extraction</strong> are allotted <strong>10%,</strong> preparing the data for analysis. <strong>Machine learning techniques</strong> are weighted at <strong>15%,</strong> 
                    being central to the research, while <strong>data science techniques</strong> contribute <strong>10%.</strong> <strong>AI techniques and interdisciplinary applications</strong> are given <strong>10%,</strong> 
                    emphasizing their role in bridging technology with culture. <strong>Model development</strong> also receives <strong>10%,</strong> and <strong>challenges,</strong>
                    <strong>future scope, and outcomes</strong> each get 5%. Finally, <strong>documentation and writing</strong> are assigned 5%, ensuring clear communication.
                </p>
            </section>
            <section>
                <h2>Data Science Techniques</h2>
            </section>
            <section>
                <h3 style="text-align: left;">Data Science Techniques (30%):</h3>
                <p class="p1">A significant portion of the research involves the collection, curation, and digitization of Sanskrit datasets. Data science methods are critical in structuring these datasets, ensuring their quality, and preparing them for machine learning and AI analysis. This foundational step is essential for building a reliable framework for further research.</p>
            </section>
            <section>
                <h2>Machine Learning Techniques</h2>
            </section>
            <section>
                <h3 style="text-align: left;">Machine Learning Techniques (40%):</h3>
                <p class="p1">
                    Machine learning plays the central role in this research, where techniques such as supervised learning, deep learning models, and natural language processing (NLP) are applied to analyze linguistic patterns in Sanskrit texts. The focus is on developing models for tasks like machine translation, sentiment analysis, syntactic analysis, and topic modeling. These ML techniques will drive the core functionality of the proposed models.
                </p>
            </section>
            <section>
                <h2>Artificial Intelligence Techniques</h2>
            </section>
            <section>
                <h3 style="text-align: left;">Artificial Intelligence Techniques (20%):</h3>
                <p class="p1">
                    Artificial intelligence techniques are employed to enhance the capabilities of the machine learning models, exploring the integration of Sanskrit with technologies like speech recognition, quantum computing, and AI-powered research tools. AI’s role is crucial for extending the applications of Sanskrit in modern technologies and advancing the research.
                </p>
            </section>
            <section>
                <h2>Interdisciplinary Applications</h2>
            </section>
            <section>
                <h3 style="text-align: left;">Interdisciplinary Applications (10%):</h3>
                <p class="p1">
                    The research also explores how Sanskrit can be used in interdisciplinary fields such as cultural preservation, philosophy, and AI ethics. These applications provide a broader context and aim to integrate Sanskrit’s linguistic and cultural heritage with the benefits of modern computational techniques.
                </p>
            </section>
            <section>
                <h2>Literature Review</h2>
            </section>
            <section>
                <p class="p1">
                    The intersection of Sanskrit and Data Science, Machine Learning (ML), and Artificial Intelligence (AI) is still an emerging field, but the structure of Sanskrit, defined by its intricate grammar (as laid out in Panini's Ashtadhyayi), makes it an ideal candidate for computational applications. Sanskrit’s precision and richness provide unique challenges and opportunities for computational linguistics and natural language processing (NLP), enabling advancements in linguistic analysis, cultural preservation, and even modern applications such as machine translation and text generation.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Sanskrit Grammar and Computational Linguistics:</h3>
                <p class="p1">
                    Panini’s Ashtadhyayi is a fundamental work in Sanskrit grammar that serves as the backbone of computational approaches to Sanskrit. The formal grammar outlined in this text provides an algorithmic approach to syntactic analysis, making it especially suitable for rule-based parsers and computational models. The ability to model Sanskrit grammar algorithmically has laid the groundwork for computational models aimed at linguistic analysis and text processing. However, one of the key challenges remains adapting Panini’s structure for modern computational tools, which are often designed for languages with less complex syntactic rules than Sanskrit.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Machine Learning Approaches for Linguistics:</h3>
                <p class="p1">
                    Recent advancements in machine learning have begun to show promise in processing and analyzing Sanskrit. BERT, GPT, and Transformer models are being adapted for Sanskrit, particularly for syntactic analysis, part-of-speech tagging, and sentiment analysis. These models, initially designed for languages like English, require significant modifications to capture the unique morphology and syntactic structures of Sanskrit. Studies have explored the application of both supervised and unsupervised learning techniques to Sanskrit datasets, with encouraging results in tasks such as text classification and topic modeling. However, the limited availability of large annotated Sanskrit datasets remains a challenge for training effective models. Deep learning, specifically recurrent neural networks (RNNs) and long short-term memory (LSTM) networks, are also being experimented with for machine translation and text generation tasks, but they require substantial computational resources and data for training.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Sanskrit NLP Tools:</h3>
                <p class="p1">
                    Tools such as the Sanskrit Heritage Reader and Sanskrit-WordNet have been developed to automate Sanskrit text analysis. The Sanskrit Heritage Reader, primarily based on rule-based systems, enables parsing and morphological analysis of Sanskrit. The Sanskrit-WordNet project aims to create a lexical database of Sanskrit to aid in machine translation and semantic analysis. While these tools have provided valuable resources for computational Sanskrit studies, the integration of machine learning models can improve their scalability and adaptability, particularly in tasks such as semantic analysis, sentence generation, and context understanding.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">AI in Sanskrit for Cultural and Educational Preservation:</h3>
                <p class="p1">
                    Beyond linguistic analysis, AI and machine learning are playing an increasing role in the preservation of Sanskrit and its rich cultural and philosophical heritage. Research on semantic analysis has revealed the potential of AI in interpreting complex philosophical texts such as the Vedas, Upanishads, and Bhagavad Gita. AI for education is another growing area, where systems are being developed to teach Sanskrit more effectively through intelligent tutoring systems. These systems use Natural Language Generation (NLG) and semantic understanding to help learners engage with Sanskrit texts, offering personalized learning experiences. Additionally, AI-powered systems are being developed for preserving Sanskrit manuscripts through digitization, image recognition, and optical character recognition (OCR) technologies, making ancient texts more accessible and easier to analyze.
                </p>
            </section>
            <section>
                <h2>Existing Research</h2>
            </section>
            <section>
                <p class="p1">
                    Several key projects and studies have contributed to the field of Sanskrit NLP, and while progress has been made, the integration of machine learning and AI with Sanskrit is still in its early stages.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Sanskrit Heritage Project:</h3>
                <p class="p1">
                    The Sanskrit Heritage Project is one of the most prominent initiatives that focus on creating a database of Sanskrit grammar and computational tools. It provides resources such as parsers and morphological analyzers based on Panini’s Ashtadhyayi. While these tools are crucial for understanding the grammatical structure of Sanskrit, the project’s scope remains somewhat limited to certain subsets of the language, and the potential for integrating machine learning and AI to process larger, more varied Sanskrit texts remains a promising area for future research.
                </p>
            </section>
             <section>
                <h3 style="text-align: left;">Sanskrit-WordNet:</h3>
                <p class="p1">
                    Sanskrit-WordNet is a lexical resource designed to improve machine translation and semantic analysis by creating a network of meaning-based relationships among Sanskrit words. This project mirrors the concept of WordNet used in other languages, enabling more nuanced NLP tasks like sentiment analysis and topic modeling. The lexical database has proved beneficial in improving semantic understanding for both humans and machines, though further work is needed to integrate this resource into broader machine learning systems for comprehensive Sanskrit text analysis.
                </p>
             </section>
            <section>
                <h3 style="text-align: left;">BERT for Sanskrit:</h3>
                <p class="p1">
                    The use of BERT and other transformer models in Sanskrit is an exciting new development in the field of Sanskrit NLP. Adapting BERT for Sanskrit requires significant modification, as its pre-training is based on languages with a simpler syntactic structure. Recent research has involved fine-tuning BERT models for Sanskrit, showing improvements in tasks like text classification and translation. However, the challenge remains in refining these models to capture the unique intricacies of Sanskrit grammar, especially when handling complex sentences or philosophical texts.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Deep Learning and Sanskrit:</h3>
                <p class="p1">
                    Deep learning models such as LSTMs and RNNs have shown promising results for machine translation between Sanskrit and modern languages, such as English and Hindi. Researchers are experimenting with these techniques for text generation and sentence parsing, but these models require extensive training data and computing power. One major limitation is the scarcity of large annotated datasets that are essential for training deep learning models effectively.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">Interdisciplinary Approaches to Sanskrit:</h3>
                <p class="p1">
                    Sanskrit research has also expanded into interdisciplinary fields, with AI being applied to areas such as philosophy, digital humanities, and computational philology. Many scholars are combining AI with traditional studies of Sanskrit’s cultural and philosophical significance. AI is being explored for knowledge representation of ancient texts, and semantic analysis is being used to study the underlying meaning and relationships within philosophical texts. The application of AI for cultural preservation is a growing field, with AI-powered tools aiding the digitization and analysis of ancient manuscripts, making them accessible for scholarly study and public engagement.
                </p>
            </section>
            <section>
                <h3 style="text-align: left;">AI for Cultural Preservation:</h3>
                <p class="p1">
                    AI’s role in cultural preservation through image recognition and OCR has revolutionized the way ancient Sanskrit manuscripts are stored and analyzed. Projects focused on digitization are enabling scholars to access historical Sanskrit texts, such as palm leaf manuscripts, that were previously difficult to preserve or share. Through OCR and text recognition technologies, handwritten or printed Sanskrit can now be digitized, enabling more efficient storage, retrieval, and analysis of these invaluable texts.
                </p>
            </section>
            <section>
                <h2>Challenges</h2>
            </section>
            <section>
                <p  class="p1">
                    <strong>Limited Datasets:</strong> Scarcity of large, annotated Sanskrit datasets hinders training machine learning models effectively.
                </p>
                <p class="p1">
                    <strong>Complex Grammar:</strong> Sanskrit's intricate grammar and inflectional system make syntactic and morphological analysis challenging.
                </p>
                <p class="p1">
                    <strong>Word Ambiguity:</strong> Multiple meanings of Sanskrit words based on context complicate semantic analysis and machine translation.</strong>
                </p>
                <p class="p1">
                    <strong>Cultural and Philosophical Context:</strong> Understanding Sanskrit’s philosophical texts requires combining linguistic analysis with cultural knowledge, which AI models may not fully capture.
                </p>
                <p class="p1">
                     <strong>Low-Resource Challenges:</strong> Training deep learning models is challenging due to the lack of comprehensive datasets for Sanskrit.
                </p>
                <p class="p1">
                    <strong>Multi-Modal Data Handling:</strong> Extracting meaningful data from non-digital formats (e.g., manuscripts, handwritten texts) requires integration of computer vision and NLP.
                </p>
                <p class="p1">
                    <strong>Interdisciplinary Collaboration:</strong> Integrating AI with Sanskrit requires collaboration across linguistics, philosophy, and AI, which is often complex due to varying expertise.
                </p>
            </section>
        </section>
    </section>
</body>
</html>
